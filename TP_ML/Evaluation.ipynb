{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group B1\n",
    "Aubut Guillaume\n",
    "Pastor Emmanuel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we consider the  (binarized) Compas dataset that we studied in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree configuration is a set of parameters that one can use to build decision trees. Propose 6 configurations that are likely to provide different topologies and caracteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* configuration 1: splitter=\"best\", max_depth=2, min_samples_leaf=50\n",
    "* configuration 2: splitter=\"best\", max_depth=4, min_samples_leaf=50\n",
    "* configuration 3: splitter=\"random\", max_depth=4, min_samples_leaf=100\n",
    "* configuration 4: splitter=\"random\", max_depth=2, min_samples_leaf=16\n",
    "* configuration 5: splitter=\"random\", max_depth=4, min_samples_leaf=4\n",
    "* configuration 6: splitter=\"best\", max_depth=8, min_samples_leaf=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree for each of the previous configurations on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree, model_selection, metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "from utils import load_from_csv\n",
    "import  pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, train_labels, features, prediction = load_from_csv(\"./compass.csv\")\n",
    "params = [[\"best\", 2, 50],\n",
    "          [\"best\", 4, 50],\n",
    "          [\"random\", 4, 100],\n",
    "          [\"random\", 2, 16],\n",
    "          [\"random\", 4, 4],\n",
    "          [\"best\", 8, 4]]\n",
    "\n",
    "for i in range(len(params)):\n",
    "    clf = tree.DecisionTreeClassifier(splitter=params[i][0], max_depth=params[i][1], min_samples_leaf=params[i][2])\n",
    "    clf = clf.fit(train_examples, train_labels)\n",
    "\n",
    "    plt.figure(figsize=(50,20))\n",
    "    tree.plot_tree(clf,feature_names= tuple(features),class_names= (prediction, \"NO_\" + prediction ),filled=True)\n",
    "    title = \"splitter=\" + str(params[i][0]) + \", max_depth=\" + str(params[i][1]) + \", min_samples_leaf=\" + str(params[i][2])\n",
    "    plt.title(title, loc=\"center\", fontdict={'fontsize': 40, 'fontweight': 'bold'})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose an evaluation in terms of training and testing accuracies using $5$-cross validation on two decision trees that have different typologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>splitter</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>testing accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.635834</td>\n",
       "      <td>0.630191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.668216</td>\n",
       "      <td>0.659586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  splitter  max_depth  min_samples_leaf  training accuracy  testing accuracy\n",
       "0     best          2                50           0.635834          0.630191\n",
       "1   random          4               100           0.668216          0.659586"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in (0,2):\n",
    "    clf = tree.DecisionTreeClassifier(splitter=params[i][0], max_depth=params[i][1], min_samples_leaf=params[i][2])\n",
    "    score = model_selection.cross_validate(clf, train_examples, train_labels, cv=5, return_train_score=True)\n",
    "    results.append({'splitter': params[i][0],\n",
    "                    'max_depth': params[i][1],\n",
    "                    'min_samples_leaf': params[i][2],\n",
    "                    'training accuracy': score['train_score'].mean(),\n",
    "                    'testing accuracy': score['test_score'].mean()})\n",
    "table = pd.DataFrame.from_dict(results)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propose an experimental study that shows the transition phase from underfitting to overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the confusion matrix on a particular good configuration (after explaining your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide an evaluation of the fairness of the model based on the False Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
